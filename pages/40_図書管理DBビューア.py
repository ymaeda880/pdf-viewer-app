# pages/40_å›³æ›¸ç®¡ç†DBãƒ“ãƒ¥ãƒ¼ã‚¢.py
# ------------------------------------------------------------
# ðŸ“š å›³æ›¸ç®¡ç†DB ãƒ“ãƒ¥ãƒ¼ã‚¢ & æ¤œç´¢
# - PATHS.library_root ã‹ã‚‰ Excel ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ—¢å®š: å›³æ›¸é¤¨DB.xlsx â†’ å›³æ›¸ç®¡ç†DB.xlsxï¼‰
# - æ–‡å­—åˆ—ã®æ¨ªæ–­ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆAND/OR, å¤§æ–‡å­—å°æ–‡å­—ï¼‰
# - ä»£è¡¨ã‚«ãƒ©ãƒ ï¼ˆã‚¿ã‚¤ãƒˆãƒ«/è‘—è€…/åˆ†é¡ž/å‡ºç‰ˆå¹´/çŠ¶æ…‹ ç­‰ï¼‰ã‚’æŽ¨å®šï¼ˆçµžã‚Šè¾¼ã¿UIã«æ´»ç”¨ï¼‰
# - è¡¨ç¤ºåˆ—ã®é¸æŠžã€ä¸¦ã³æ›¿ãˆã€CSV/Excel ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# - ã‚·ãƒ¼ãƒˆé¸æŠžï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆå¯¾å¿œï¼‰
# - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ä¸€æ™‚å·®ã—æ›¿ãˆ
# - æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å„ªå…ˆï¼ˆData Editorï¼‰/ é«˜é€Ÿè¡¨ç¤ºï¼ˆDataFrameï¼‰ã‚’åˆ‡æ›¿å¯èƒ½
# - å¹´ç¯„å›²ã¯ select_slider ã§ç«¯ãƒ©ãƒ™ãƒ«ã®è¦‹åˆ‡ã‚Œã‚’å›žé¿
# - ç™ºè¡Œå¹´ãŒ4æ¡ã§ãªã„è¡Œã¯ä¸¦ã³æ›¿ãˆã§æœ«å°¾ã«å›žã™
# - é–‹ç™ºæ™‚ã¯å…ˆé ­ N ä»¶ã®ã¿èª­ã‚€ï¼ˆå…¨ä»¶èª­ã¿è¾¼ã¿ã‚‚é¸æŠžå¯ï¼‰
# - â˜… æ–°æ©Ÿèƒ½: æŒ‡å®š7ã‚«ãƒ©ãƒ ã ã‘ã‚’ä¸€ç™ºã§è¡¨ç¤ºã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
#   ï¼ˆç™»éŒ²ç•ªå·, ã‚¿ã‚¤ãƒˆãƒ«, ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰, ç·¨ãƒ»è‘—è€…å, ç™ºè¡Œç¤¾å, ç™ºè¡Œå¹´, ä¿®æ­£æ—¥ï¼‰
# - â˜… ä»•æ§˜å¤‰æ›´: ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆæ¤œç´¢ï¼ˆISBN/è«‹æ±‚è¨˜å·ï¼‰ã¯çœç•¥
# ------------------------------------------------------------
from __future__ import annotations
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import io
import re

import pandas as pd
import streamlit as st

from lib.app_paths import PATHS

st.set_page_config(page_title="å›³æ›¸ç®¡ç†DB ãƒ“ãƒ¥ãƒ¼ã‚¢", page_icon="ðŸ“š", layout="wide")
st.title("ðŸ“š å›³æ›¸ç®¡ç†DB ãƒ“ãƒ¥ãƒ¼ã‚¢ & æ¤œç´¢")

# ========= ãƒ‘ã‚¹ã¨æ—¢å®šãƒ•ã‚¡ã‚¤ãƒ«è§£æ±º =========
LIB_ROOT = Path(PATHS.library_root)
DEFAULT_CANDIDATES = ["å›³æ›¸é¤¨DB.xlsx", "å›³æ›¸ç®¡ç†DB.xlsx"]

def _pick_default_xlsx(root: Path) -> Optional[Path]:
    for name in DEFAULT_CANDIDATES:
        p = (root / name)
        if p.exists():
            return p
    xs = sorted(root.glob("*.xlsx"))
    return xs[0] if xs else None

# ========= ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãèª­ã¿è¾¼ã¿ =========
@st.cache_data(show_spinner=True)
def load_excel(path_or_bytes, sheet_name: Optional[str]) -> Tuple[pd.DataFrame, List[str]]:
    """Excelã‚’èª­ã¿è¾¼ã¿ã€(df, ã‚·ãƒ¼ãƒˆåä¸€è¦§) ã‚’è¿”ã™ã€‚"""
    if isinstance(path_or_bytes, (str, Path)):
        xls = pd.ExcelFile(path_or_bytes)  # engine è‡ªå‹•ï¼ˆopenpyxlï¼‰
    else:
        xls = pd.ExcelFile(io.BytesIO(path_or_bytes))
    sheets = xls.sheet_names
    target_sheet = sheet_name if (sheet_name in sheets) else sheets[0]
    df = xls.parse(target_sheet, dtype=str)  # æ–‡å­—åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¿â†’æ¤œç´¢ãŒå®‰å®š
    # å‰å¾Œç©ºç™½é™¤åŽ»ï¼ˆapplymap ã¯å°†æ¥éžæŽ¨å¥¨ãªã®ã§ map äº’æ›ã§ï¼‰
    for c in df.columns:
        df[c] = df[c].map(lambda x: x.strip() if isinstance(x, str) else x)
    return df, sheets

# ========= ã‚«ãƒ©ãƒ æŽ¨å®šï¼ˆã‚ˆãã‚ã‚‹æ—¥æœ¬èªžåï¼‰ =========
CAND = {
    "title": {"ã‚¿ã‚¤ãƒˆãƒ«","æ›¸å","é¡Œå","Title","ã‚¿ã‚¤ãƒˆãƒ«å"},
    "author": {"è‘—è€…","ä½œè€…","ç·¨è€…","Author","ç·¨ãƒ»è‘—è€…å"},
    "publisher": {"ç™ºè¡Œç¤¾å","å‡ºç‰ˆç¤¾","ç™ºè¡Œ","Publisher","ç™ºè¡Œæ‰€"},
    "year": {"ç™ºè¡Œå¹´","å‡ºç‰ˆå¹´","åˆŠè¡Œå¹´","ç™ºè¡Œå¹´æœˆ","Year"},
    "category": {"åˆ†é¡ž","ã‚«ãƒ†ã‚´ãƒª","ã‚«ãƒ†ã‚´ãƒªãƒ¼","NDC","ã‚¸ãƒ£ãƒ³ãƒ«"},
    "status": {"çŠ¶æ…‹","ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹","è²¸å‡ºçŠ¶æ³","åœ¨åº«","Availability"},
    "id": {"ç™»éŒ²ç•ªå·","ç™»éŒ²No.","ç™»éŒ²ç•ªå·ï¼ˆç¤¾å†…ï¼‰","ID","ç®¡ç†ç•ªå·"},
    "keyword": {"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰","KW","Keywords"},
    "updated": {"ä¿®æ­£æ—¥","æ›´æ–°æ—¥","æœ€çµ‚æ›´æ–°"},
}

def pick_cols(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    cols = list(df.columns)
    found: Dict[str, Optional[str]] = {k: None for k in CAND}
    for key, candidates in CAND.items():
        for c in cols:
            if c in candidates:
                found[key] = c
                break
    return found

# å¹´æŠ½å‡ºï¼ˆ4æ¡ã ã‘è¿”ã™ã€ãªã‘ã‚Œã° Noneï¼‰
def _extract_year(v) -> Optional[int]:
    if v is None:
        return None
    s = str(v)
    m = re.search(r"(\d{4})", s)
    if not m:
        return None
    y = int(m.group(1))
    if 1000 <= y <= 2100:
        return y
    return None

# ========= ã‚µã‚¤ãƒ‰ãƒãƒ¼ =========
with st.sidebar:
    st.header("ðŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")
    st.caption(f"library_root: {LIB_ROOT}")
    default_path = _pick_default_xlsx(LIB_ROOT)
    path_text = st.text_input(
        "Excel ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
        value=str(default_path or (LIB_ROOT / "å›³æ›¸é¤¨DB.xlsx"))
    ).strip()
    uploaded = st.file_uploader("ä¸€æ™‚çš„ã«åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ã†ï¼ˆ.xlsxï¼‰", type=["xlsx"])

    # èª­ã¿è¾¼ã¿
    try:
        if uploaded is not None:
            df0, sheets = load_excel(uploaded.getvalue(), sheet_name=None)
            current_source = f"(uploaded) {uploaded.name}"
        else:
            target_path = Path(path_text).expanduser().resolve()
            if not target_path.exists():
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_path}")
                st.stop()
            df0, sheets = load_excel(str(target_path), sheet_name=None)
            current_source = str(target_path)
    except Exception as e:
        st.error(f"Excel èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()

    # é–‹ç™ºæ™‚ã®èª­ã¿è¾¼ã¿ä»¶æ•°åˆ¶é™
    DEV_MAX_ROWS = st.number_input("å…ˆé ­ N ä»¶ã ã‘èª­ã‚€ï¼ˆ0ã§å…¨ä»¶ï¼‰", 0, 100_000, 500, 50)
    sheet = st.selectbox("ã‚·ãƒ¼ãƒˆ", sheets, index=0)

    # æŒ‡å®šã‚·ãƒ¼ãƒˆã§å†èª­è¾¼ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯åŠ¹ãï¼‰
    if uploaded is not None:
        df, _ = load_excel(uploaded.getvalue(), sheet)
    else:
        df, _ = load_excel(str(Path(current_source)), sheet)

    if DEV_MAX_ROWS and len(df) > DEV_MAX_ROWS:
        df = df.head(int(DEV_MAX_ROWS))

    st.caption(f"èª­ã¿è¾¼ã¿å…ƒ: {current_source}")

    st.divider()
    st.header("ðŸ”Ž æ¤œç´¢ãƒ»çµžã‚Šè¾¼ã¿")

    # ã‚«ãƒ©ãƒ æŽ¨å®š
    COL = pick_cols(df)

    # æ¤œç´¢å¯¾è±¡åˆ—ï¼ˆæ—¢å®šã¯ä»£è¡¨åˆ—ï¼‰
    default_search_cols = [c for c in [COL.get("title"), COL.get("author"), COL.get("publisher"), COL.get("keyword")] if c]
    search_cols = st.multiselect(
        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®å¯¾è±¡åˆ—",
        options=list(df.columns),
        default=default_search_cols or list(df.columns)[:4]
    )

    q = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç©ºç™½åŒºåˆ‡ã‚Šï¼‰", value="")
    mode = st.radio("ãƒ¢ãƒ¼ãƒ‰", ["AND", "OR"], index=0, horizontal=True)
    case_sensitive = st.checkbox("å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥", value=False)
    use_regex = st.checkbox("æ­£è¦è¡¨ç¾", value=False)

    # ã‚ˆãä½¿ã†çµžã‚Šè¾¼ã¿ï¼ˆå¹´ï¼‰
    st.subheader("ã‚ˆãä½¿ã†çµžã‚Šè¾¼ã¿ï¼ˆã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°è¡¨ç¤ºï¼‰")

    filters: Dict[str, object] = {}

    # å¹´ç¯„å›²ï¼ˆselect_slider ã§ç«¯ãƒ©ãƒ™ãƒ«è¦‹åˆ‡ã‚Œå›žé¿ï¼‰
    if COL.get("year"):
        years_extracted = sorted(
            {y for y in (_extract_year(v) for v in df[COL["year"]].dropna().unique()) if y is not None}
        )
        if years_extracted:
            y_min, y_max = years_extracted[0], years_extracted[-1]
            st.caption(f"ç¯„å›²ï¼ˆæœ€å°/æœ€å¤§ï¼‰: **{y_min} â€“ {y_max}**")
            sel_y1, sel_y2 = st.select_slider(
                f"{COL['year']} ç¯„å›²",
                options=years_extracted,
                value=(y_min, y_max),
                label_visibility="visible",
            )
            st.caption(f"é¸æŠžä¸­: **{sel_y1} â€“ {sel_y2}**")
            filters["year_range"] = (sel_y1, sel_y2)

    # è¡¨ç¤ºè¨­å®š
    st.divider()
    st.header("è¡¨ç¤ºè¨­å®š")

    # è¡¨ç¤ºåˆ—ã®åˆæœŸå€¤ï¼šä»£è¡¨åˆ—ãŒã‚ã‚Œã°ãã‚Œã‚’ã€ãªã‘ã‚Œã°å…ˆé ­8åˆ—
    default_show_cols = [c for c in [
        COL.get("id"), COL.get("title"), COL.get("keyword"),
        COL.get("author"), COL.get("publisher"),
        COL.get("year"), COL.get("updated")
    ] if c] or list(df.columns)[:8]

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ç¾åœ¨ã®é¸æŠžã‚’ä¿æŒ
    if "lib_show_cols" not in st.session_state:
        st.session_state["lib_show_cols"] = default_show_cols

    # â˜… ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§7ã‚«ãƒ©ãƒ ã«ã™ã‚‹ãƒœã‚¿ãƒ³
    LIB_STD_SET = ["ç™»éŒ²ç•ªå·","ã‚¿ã‚¤ãƒˆãƒ«","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰","ç·¨ãƒ»è‘—è€…å","ç™ºè¡Œç¤¾å","ç™ºè¡Œå¹´","ä¿®æ­£æ—¥"]
    if st.button("ðŸ“‹ æŒ‡å®š7ã‚«ãƒ©ãƒ ã ã‘è¡¨ç¤ºï¼ˆç™»éŒ²ç•ªå·/ã‚¿ã‚¤ãƒˆãƒ«/â€¦/ä¿®æ­£æ—¥ï¼‰"):
        # å®Ÿãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã‚‚ã®ã ã‘ã«çµžã‚‹
        st.session_state["lib_show_cols"] = [c for c in LIB_STD_SET if c in df.columns]

    show_cols = st.multiselect(
        "è¡¨ç¤ºåˆ—", list(df.columns),
        default=st.session_state["lib_show_cols"]
    )
    # ä¿å­˜
    st.session_state["lib_show_cols"] = show_cols

    sort_cols = st.multiselect(
        "ä¸¦ã³æ›¿ãˆã‚­ãƒ¼", list(df.columns),
        default=[COL["title"]] if COL.get("title") else []
    )
    ascending = st.checkbox("æ˜‡é †ã§ä¸¦ã¹æ›¿ãˆ", value=True)

    # è¡¨ã®è¡¨ç¤ºæ–¹æ³•
    view_mode = st.radio("è¡¨ã®è¡¨ç¤ºæ–¹æ³•", ["é«˜é€Ÿè¡¨ç¤ºï¼ˆDataFrameï¼‰", "æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å„ªå…ˆï¼ˆData Editorï¼‰"], index=1)
    col_width = st.slider("åˆ—å¹…(px)ï¼ˆData Editoræ™‚ï¼‰", 80, 400, 160, 10)

# ========= æ¤œç´¢é©ç”¨ =========
def _match_keywords(val: str, pats: List[re.Pattern], mode: str) -> bool:
    s = "" if val is None else str(val)
    if mode == "AND":
        return all(p.search(s) for p in pats)
    return any(p.search(s) for p in pats)

# 1) ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
if q.strip():
    tokens = [t for t in q.split() if t.strip()]
    flags = 0 if case_sensitive else re.IGNORECASE
    pats = []
    for t in tokens:
        try:
            pats.append(re.compile(t if use_regex else re.escape(t), flags))
        except re.error:
            pats.append(re.compile(re.escape(t), flags))
    mask = pd.Series(False, index=df.index)
    for col in (search_cols or df.columns):
        mask = mask | df[col].astype(str).apply(lambda s: _match_keywords(s, pats, mode))
    df = df[mask]

# 2) å¹´ç¯„å›²
if filters.get("year_range") and COL.get("year"):
    y1, y2 = filters["year_range"]
    def _in_range(v) -> bool:
        y = _extract_year(v)
        return (y is not None) and (y1 <= y <= y2)
    df = df[df[COL["year"]].apply(_in_range)]

# 3) ä¸¦ã³æ›¿ãˆï¼ˆç™ºè¡Œå¹´ã¯4æ¡åŒ–ã—ãŸã‚­ãƒ¼ã§æœ«å°¾é€ã‚Šã‚’å®Ÿç¾ï¼‰
if sort_cols:
    def _year_key(s):
        y = _extract_year(s)
        # None ã‚’æœ«å°¾ã¸ï¼ˆtuple ã® 1ç•ªç›®ã§åˆ¶å¾¡ï¼‰
        return (1, "") if y is None else (0, y)
    try:
        by = []
        for c in sort_cols:
            if COL.get("year") == c:
                by.append(df[c].map(_year_key))
            else:
                by.append(df[c].astype(str))
        df = df.assign(**{f"__sort{i}": by[i] for i in range(len(by))})
        df = df.sort_values([f"__sort{i}" for i in range(len(by))], ascending=ascending, na_position="last")
        df = df.drop(columns=[c for c in df.columns if c.startswith("__sort")])
    except Exception:
        pass

# ========= æ¦‚è¦ãƒ»DL =========
st.metric("ãƒ’ãƒƒãƒˆä»¶æ•°", f"{len(df):,}")

# è¡¨ç¤ºåˆ—ç¢ºå®š
cols_to_show = [c for c in (show_cols or list(df.columns)) if c in df.columns]
if not cols_to_show:
    cols_to_show = list(df.columns)

# è¡¨è¡¨ç¤º
if view_mode.startswith("æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«"):
    col_cfg = {c: st.column_config.Column(width=int(col_width)) for c in cols_to_show}
    st.data_editor(
        df[cols_to_show],
        width="stretch",
        height=520,
        disabled=True,
        hide_index=True,
        column_config=col_cfg,
        key="lib_de",
    )
else:
    st.dataframe(df[cols_to_show], width="stretch", height=520)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
c1, c2 = st.columns(2)
with c1:
    csv_bytes = df[cols_to_show].to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ðŸ“¥ CSV ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_bytes,
        file_name="library_filtered.csv",
        mime="text/csv",
        width="stretch",
    )
with c2:
    out = io.BytesIO()
    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        df[cols_to_show].to_excel(writer, index=False, sheet_name="filtered")
    st.download_button(
        "ðŸ“¥ Excel ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=out.getvalue(),
        file_name="library_filtered.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width="stretch",
    )

# ========= ä»£è¡¨ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ’ãƒ³ãƒˆ =========
missing = []
for k in ["id","title","keyword","author","publisher","year","updated"]:
    if k not in CAND: 
        continue
    if not pick_cols(df).get(k):
        missing.append(k)

if missing:
    with st.expander("â„¹ï¸ ã‚«ãƒ©ãƒ è‡ªå‹•æŽ¨å®šã«ã¤ã„ã¦ï¼ˆä¸è¶³ã‚ã‚Šï¼‰"):
        st.write("ä»¥ä¸‹ã®ä»£è¡¨ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ—åã‚’æ¬¡ã®ã„ãšã‚Œã‹ã¸è¿‘ã¥ã‘ã‚‹ã¨UIãŒã‚ˆã‚Šä¾¿åˆ©ã«ãªã‚Šã¾ã™ã€‚")
        for k in missing:
            st.write(f"- **{k}** å€™è£œ: {sorted(list(CAND[k]))}")
